{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7df47ab-038c-4362-814a-4903b0be6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch \n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "import numpy as np\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14884026-f814-42b1-9765-ec6ed3b8eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f7311c-383d-40eb-bdb5-317ad09eafb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d932e9c7-ee60-430f-a181-d5e653977ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ade31d-26e8-4081-b558-c9c087768c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"id\" in data.columns and \"day\" in data.columns:\n",
    "    \n",
    "    data.drop([\"id\", \"day\"], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b9693d-3cdc-4406-9253-c54006717e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"rainfall\", axis = 1)\n",
    "y = data[\"rainfall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f60425-6268-408e-957a-7209fd2526fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2190, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42ba6a33-684d-48f9-a6d8-c783ff3f001d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rainfall\n",
       "1    0.753425\n",
       "0    0.246575\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"rainfall\"].value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0382b2a4-3e85-4b39-abff-364f69839c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35547e4c-8d54-40ff-b552-efc0f81b08c2",
   "metadata": {},
   "source": [
    "# Standardised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8fb4d02d-7ea6-49df-8b14-505db7da9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.to_numpy()\n",
    "X_test_np = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fff67546-36bf-49da-81ab-cd38f7ab2d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Std = StandardScaler()\n",
    "\n",
    "X_std = Std.fit_transform(X_train)\n",
    "X_t_std = Std.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6b3ee351-a0e0-4552-afd6-0da7e6133b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_std, device = device, dtype = torch.float32)\n",
    "X_test = torch.tensor(X_t_std, device = device, dtype = torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ee99818d-954f-4635-80d5-3fcdb566eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.T\n",
    "y_train = y_train.values.reshape(1,-1)\n",
    "\n",
    "X_test = X_test.T\n",
    "y_test = y_test.values.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a0b0ec60-0f93-4086-9ef8-9d851c8e0d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([10, 1752])\n",
      "y_train shape: (1, 1752)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "680edd5e-d09c-4d4d-bd07-8c9292947ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e1aa57fd-a571-46b1-8771-42240225dfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1752])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398876a6-b0ad-4726-8e36-ca2a0930c6d2",
   "metadata": {},
   "source": [
    "# Weights Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2c424b5d-edbf-47b5-8385-babc4ea8ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "w1 = torch.randn([10, 10], dtype = torch.float32, device = device, requires_grad = True)\n",
    "b1 = torch.full([10,1], 0.01, dtype = torch.float32, device = device, requires_grad = True)\n",
    "\n",
    "\n",
    "w2 = torch.randn([1, 10], dtype = torch.float32, device = device, requires_grad = True)\n",
    "b2 = torch.full([1,1],0.01, dtype = torch.float32, device = device, requires_grad = True)\n",
    "\n",
    "          \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5f2e8f89-0376-48ee-bfd9-07391f377c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "\"lr\" : [0.1, 0.01, 0.001, 0.0001],\n",
    "\"ite\" : [100, 1000, 10000, 100000],\n",
    "\"batch_size\" : [16, 32, 64, 128, 256, 512]\n",
    "}\n",
    "\n",
    "Results = []\n",
    "best_params = {}\n",
    "best_accuracy = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d17b49-480a-47d9-b582-678df29769d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a2ad2855-49af-4f14-85b1-194f072d6897",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for lr in params_grid[\"lr\"]:\n",
    "    for ite in params_grid[\"ite\"]:\n",
    "        for batch_size in params_grid[\"batch_size\"]:\n",
    "            for i in range(ite):\n",
    "            \n",
    "                idx = torch.randint(0, X_train.shape[1], (batch_size, ))\n",
    "                X_sample = X_train[:, idx]\n",
    "                y_sample = y_train[:, idx]\n",
    "            \n",
    "                Z1 = torch.matmul(w1, X_sample) + b1\n",
    "                A1 = torch.relu(Z1)\n",
    "                                                    \n",
    "                Z2 = torch.matmul(w2, A1) + b2\n",
    "                A2 = torch.sigmoid(Z2)\n",
    "            \n",
    "            \n",
    "            \n",
    "                loss = -torch.mean((y_sample*torch.log(A2)) + ((1-y_sample)*torch.log(1-A2)))\n",
    "            \n",
    "                loss.backward()\n",
    "            \n",
    "                with torch.no_grad():\n",
    "            \n",
    "                    w1 -= lr * w1.grad\n",
    "                    b1 -= lr * b1.grad\n",
    "            \n",
    "                    w2 -= lr * w2.grad\n",
    "                    b2 -= lr * b2.grad\n",
    "            \n",
    "            \n",
    "            \n",
    "                w1.grad.zero_()\n",
    "                b1.grad.zero_()\n",
    "                w2.grad.zero_()\n",
    "                b2.grad.zero_()\n",
    "            \n",
    "                #if i%100000 == 0:\n",
    "                    #print(f\"At Iteration {i}, Loss = {loss}\")\n",
    "        \n",
    "            final_Z1 = torch.matmul(w1, X_test) + b1\n",
    "            final_A1 = torch.relu(final_Z1)\n",
    "            \n",
    "            final_Z2 = torch.matmul(w2, final_A1) + b2\n",
    "            final_A2 = torch.sigmoid(final_Z2)\n",
    "            \n",
    "            y_pred = (final_A2 >= 0.5).int()\n",
    "            \n",
    "            Accuracy = (y_test == y_pred).float().mean().item()\n",
    "    \n",
    "            \n",
    "            Results.append({\n",
    "                \"Learning_rate\" : lr,\n",
    "                \"Iteration\" : ite,\n",
    "                \"Batch_size\": batch_size,\n",
    "                \"Accuracy\" : Accuracy,\n",
    "                \"loss\" : loss.item(), \n",
    "                \n",
    "            })\n",
    "    \n",
    "            if Accuracy >= best_accuracy:\n",
    "                best_accuracy = Accuracy \n",
    "    \n",
    "                best_params = {\n",
    "                    \"Ite\" : ite,\n",
    "                    \"Learning_rate\" : lr,\n",
    "                    \"batch_size\" : batch_size,\n",
    "                    \"Accuracy\" : Accuracy\n",
    "                }\n",
    "\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f7790996-6633-4a60-9f15-c6e292774a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ite': 1000,\n",
       " 'Learning_rate': 0.1,\n",
       " 'batch_size': 512,\n",
       " 'Accuracy': 0.8493150472640991}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6b1fbfdf-479b-4194-a073-e980d719286a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5099633932113647"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee145aff-86fc-4709-b309-314b214fbb12",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0d7bfefe-d93c-48dc-8c7e-36895faa11ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 438])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "143846c3-14ba-48a5-8728-fabebbdabfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_Z1 = torch.matmul(w1, X_test) + b1\n",
    "final_A1 = torch.relu(final_Z1)\n",
    "\n",
    "final_Z2 = torch.matmul(w2, final_A1) + b2\n",
    "final_A2 = torch.sigmoid(final_Z2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "04b9ea36-cea4-4398-9bfc-f91b820a3622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.1172e-01, 7.6232e-01, 4.8169e-01, 9.5808e-01, 9.6560e-01, 9.9058e-01,\n",
       "         9.9076e-01, 9.2262e-01, 7.0839e-01, 9.6504e-01, 9.8487e-01, 8.8726e-01,\n",
       "         6.4536e-01, 1.0850e-01, 3.2694e-01, 7.1136e-01, 9.6697e-01, 8.5379e-01,\n",
       "         8.1677e-01, 6.7105e-02, 4.8086e-01, 9.8681e-01, 2.1076e-01, 9.3232e-01,\n",
       "         3.7371e-02, 9.7269e-01, 8.3395e-01, 7.7542e-01, 9.1609e-01, 9.7966e-01,\n",
       "         9.9125e-01, 9.0154e-01, 9.0527e-01, 7.1159e-02, 3.6512e-02, 9.9062e-01,\n",
       "         9.2626e-01, 9.8183e-01, 6.3955e-01, 3.8964e-01, 9.0763e-01, 9.0056e-01,\n",
       "         9.8331e-01, 9.6483e-01, 9.5170e-01, 9.8514e-01, 7.3565e-01, 9.6929e-01,\n",
       "         2.0873e-01, 8.9131e-01, 9.6151e-01, 1.2251e-01, 9.6514e-01, 9.7198e-01,\n",
       "         9.0863e-01, 4.0659e-01, 9.2132e-01, 9.7611e-01, 9.6962e-01, 7.8780e-01,\n",
       "         5.0257e-01, 9.8070e-01, 9.5479e-01, 9.8337e-01, 9.8388e-01, 8.6632e-01,\n",
       "         9.5961e-01, 9.6981e-01, 9.6123e-01, 7.1251e-01, 9.5791e-01, 9.7655e-01,\n",
       "         8.3834e-01, 9.7026e-01, 9.0320e-02, 8.3677e-01, 7.3092e-01, 9.6230e-01,\n",
       "         7.4546e-01, 2.3954e-01, 8.0368e-01, 9.5454e-01, 3.4818e-01, 9.1912e-01,\n",
       "         9.1574e-01, 9.8862e-01, 9.2155e-01, 6.8534e-01, 9.7779e-01, 8.4207e-01,\n",
       "         9.5556e-01, 9.6062e-01, 2.7621e-01, 9.4720e-02, 8.5549e-01, 8.1540e-01,\n",
       "         9.8670e-01, 9.6164e-01, 2.2765e-01, 9.8098e-01, 8.8323e-01, 3.3690e-01,\n",
       "         5.9043e-01, 9.3555e-01, 5.6542e-01, 7.9614e-01, 9.2816e-01, 9.9501e-01,\n",
       "         9.4086e-01, 9.9331e-01, 5.2718e-03, 9.5465e-01, 9.8598e-01, 7.0064e-01,\n",
       "         8.5537e-01, 9.7641e-01, 7.7672e-01, 9.4895e-01, 9.2152e-01, 9.9109e-01,\n",
       "         8.9294e-01, 9.8256e-01, 9.9477e-01, 6.6132e-01, 7.8905e-01, 9.9678e-01,\n",
       "         2.0795e-01, 9.4793e-01, 9.8660e-01, 9.2605e-01, 6.4865e-01, 7.0663e-01,\n",
       "         9.8207e-01, 9.1771e-01, 9.8933e-01, 9.6159e-01, 9.1276e-01, 3.7229e-01,\n",
       "         3.7582e-01, 9.7856e-01, 1.2030e-01, 5.9534e-01, 9.9162e-01, 7.8242e-01,\n",
       "         3.0721e-01, 9.1831e-01, 9.8738e-01, 9.7013e-01, 8.5995e-01, 8.9401e-01,\n",
       "         8.5471e-01, 9.8380e-01, 8.8868e-01, 1.4425e-01, 8.9749e-01, 6.7026e-01,\n",
       "         9.8632e-01, 9.8983e-01, 9.6086e-01, 2.7277e-01, 9.8059e-01, 9.2900e-01,\n",
       "         2.1136e-01, 7.8820e-01, 9.7423e-01, 9.9045e-01, 9.4679e-01, 9.3337e-01,\n",
       "         1.4999e-01, 6.0998e-01, 9.4910e-01, 6.3925e-01, 9.9298e-01, 5.1247e-01,\n",
       "         1.1543e-02, 9.3123e-01, 9.8926e-01, 9.9155e-01, 7.1789e-01, 9.9268e-01,\n",
       "         9.7719e-01, 9.8837e-01, 9.9013e-01, 9.8838e-01, 9.0701e-01, 7.3362e-01,\n",
       "         8.6012e-02, 8.9804e-01, 7.9026e-01, 9.4993e-01, 9.6803e-02, 9.9396e-01,\n",
       "         9.2298e-01, 9.1493e-01, 9.0358e-01, 8.2346e-02, 9.3996e-03, 3.6266e-01,\n",
       "         9.8896e-01, 3.2912e-01, 7.6947e-01, 6.3286e-01, 9.7824e-01, 8.2163e-01,\n",
       "         6.0606e-01, 2.7933e-01, 8.9510e-01, 9.5794e-01, 9.8649e-01, 9.3635e-01,\n",
       "         9.4893e-01, 9.5682e-01, 4.3588e-01, 9.9434e-01, 9.9102e-01, 6.8184e-01,\n",
       "         9.9332e-01, 9.6614e-01, 9.9280e-01, 9.8474e-01, 4.7223e-01, 9.9360e-01,\n",
       "         9.5582e-01, 9.8982e-01, 1.5166e-02, 9.6885e-01, 9.6459e-01, 8.6716e-01,\n",
       "         9.1743e-01, 2.6090e-02, 9.8559e-01, 7.6002e-01, 8.7262e-02, 9.9773e-01,\n",
       "         1.1638e-01, 7.5719e-04, 2.3146e-01, 9.7459e-01, 8.5100e-01, 9.3602e-01,\n",
       "         9.8943e-01, 8.1264e-01, 9.9412e-01, 4.1130e-02, 7.2788e-01, 1.4664e-01,\n",
       "         7.7674e-01, 5.3480e-01, 2.8011e-01, 9.6602e-01, 9.6255e-01, 8.5285e-01,\n",
       "         9.9518e-01, 8.5050e-01, 5.9296e-01, 4.8595e-01, 9.8021e-01, 8.9300e-01,\n",
       "         9.8500e-01, 7.8828e-01, 4.6462e-01, 8.0541e-01, 9.4031e-01, 8.4428e-02,\n",
       "         1.8592e-01, 8.5393e-01, 9.3808e-01, 4.1028e-02, 8.9881e-01, 9.4692e-01,\n",
       "         9.5833e-01, 9.6355e-01, 6.1022e-01, 4.3251e-01, 5.7451e-01, 8.8229e-01,\n",
       "         5.1302e-02, 8.6652e-01, 7.7034e-01, 8.8686e-01, 9.7999e-01, 8.5510e-01,\n",
       "         9.8772e-01, 9.8959e-01, 9.5741e-01, 9.7796e-01, 9.2739e-01, 9.6346e-01,\n",
       "         2.2032e-01, 9.7936e-01, 6.9078e-01, 9.8983e-01, 9.8285e-01, 6.9744e-01,\n",
       "         9.9417e-01, 8.5219e-01, 8.5190e-01, 9.6049e-01, 9.6492e-01, 9.5250e-01,\n",
       "         1.4674e-01, 8.0508e-01, 9.7813e-01, 8.4660e-01, 6.3105e-01, 9.9024e-01,\n",
       "         9.0988e-01, 9.6744e-01, 9.9092e-01, 1.7115e-01, 7.4189e-01, 9.3740e-01,\n",
       "         9.9344e-01, 9.4255e-01, 9.1596e-01, 6.1441e-01, 3.4753e-01, 9.7824e-01,\n",
       "         9.8122e-01, 9.4688e-01, 3.6041e-02, 9.6906e-01, 9.3770e-01, 7.9154e-01,\n",
       "         7.6997e-01, 4.1073e-01, 9.7949e-01, 4.0431e-01, 8.7315e-01, 1.3534e-01,\n",
       "         8.3360e-01, 8.5347e-01, 6.8043e-01, 9.6128e-01, 9.5147e-01, 9.4338e-01,\n",
       "         9.4369e-01, 8.8528e-01, 9.1682e-01, 2.5248e-01, 8.5108e-01, 9.6207e-01,\n",
       "         9.5518e-01, 9.9272e-01, 9.9510e-01, 7.3123e-02, 9.9047e-01, 1.0096e-01,\n",
       "         1.6909e-03, 9.6240e-01, 9.7694e-01, 9.8225e-01, 9.8924e-01, 9.8742e-01,\n",
       "         9.7498e-01, 1.8251e-01, 4.2952e-01, 1.9601e-01, 9.9388e-01, 1.7966e-01,\n",
       "         9.8726e-01, 1.4315e-01, 9.8135e-01, 9.4113e-01, 5.7050e-01, 8.9271e-01,\n",
       "         9.7687e-01, 9.9034e-01, 9.2964e-01, 8.3763e-01, 9.7598e-01, 9.1551e-01,\n",
       "         1.5811e-01, 9.8410e-01, 9.1586e-01, 9.1524e-01, 8.6618e-01, 5.6625e-01,\n",
       "         5.5884e-01, 9.7745e-01, 4.8136e-01, 3.4616e-01, 4.3495e-01, 9.8731e-01,\n",
       "         9.8612e-01, 8.7670e-01, 7.7665e-01, 8.4127e-02, 9.5043e-01, 9.9159e-01,\n",
       "         9.1751e-01, 9.7392e-01, 3.7422e-01, 9.7749e-01, 9.5790e-01, 6.0912e-01,\n",
       "         1.6602e-02, 9.0467e-01, 8.1552e-01, 9.9133e-01, 9.8624e-01, 7.9048e-01,\n",
       "         8.4076e-01, 7.5987e-01, 9.7984e-01, 2.3208e-01, 9.8885e-01, 9.8232e-01,\n",
       "         3.1402e-01, 9.8135e-01, 9.7496e-01, 9.1608e-01, 1.4285e-01, 9.9695e-01,\n",
       "         1.1917e-01, 9.8410e-01, 4.3416e-01, 9.7651e-01, 9.8089e-01, 9.0223e-01,\n",
       "         7.0487e-02, 9.9145e-01, 1.1678e-02, 9.8532e-01, 4.3142e-02, 4.3764e-01,\n",
       "         3.5620e-02, 8.4325e-01, 9.4623e-01, 8.1946e-01, 9.8437e-01, 9.0540e-01,\n",
       "         9.8402e-01, 4.2617e-01, 9.9256e-01, 9.6580e-01, 8.0510e-01, 9.7350e-01]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3fa759a7-e94c-48d0-a482-04e2ff9e89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (final_A2 >= 0.5).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "65ee57da-6a97-4e4f-9399-b6cb65b1a5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pf/zt0rv__534x98dp9tc0g2lvw0000gn/T/ipykernel_6529/4039250140.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test, dtype = torch.float32)\n"
     ]
    }
   ],
   "source": [
    "y_test = torch.tensor(y_test, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ba848acc-de11-4bcf-ac7e-77c23c9a5b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.844748854637146"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test == y_pred).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe4cf8-0e11-4d91-8f07-ed0d3efe582b",
   "metadata": {},
   "source": [
    "# Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e63451ba-811d-4e5e-ab78-82a741e59d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e01d9b55-8877-476a-bb6f-48e496735289",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_test.drop([\"id\", \"day\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "af8ac36f-e137-4ea9-b0dc-cd6c4e4e9e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pressure         0\n",
       "maxtemp          0\n",
       "temparature      0\n",
       "mintemp          0\n",
       "dewpoint         0\n",
       "humidity         0\n",
       "cloud            0\n",
       "sunshine         0\n",
       "winddirection    1\n",
       "windspeed        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3cab3a1-a6f0-412e-a1f5-f0822aed3f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pf/zt0rv__534x98dp9tc0g2lvw0000gn/T/ipykernel_6529/3069420807.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  k_test[\"winddirection\"].fillna(k_test[\"winddirection\"].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "k_test[\"winddirection\"].fillna(k_test[\"winddirection\"].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a889aea2-3cd3-4b7f-9080-dff7296b9448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pressure         0\n",
       "maxtemp          0\n",
       "temparature      0\n",
       "mintemp          0\n",
       "dewpoint         0\n",
       "humidity         0\n",
       "cloud            0\n",
       "sunshine         0\n",
       "winddirection    0\n",
       "windspeed        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d8cb98a-fbcb-41f6-b51d-eda8509c5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_test_std = Std.transform(k_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "801d54e8-437c-4f8b-a073-2a9b775546d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_test = torch.tensor(k_test_std, device = device, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b57d4bf-b46e-4a31-8ce8-4aa6f4bf5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_test = k_test.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c71a62e-8de1-4ab9-9f63-da234597d12f",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c21f9a54-64d8-47b3-876c-0772dab1d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Z1 = torch.matmul(w1, k_test) + b1\n",
    "test_A1 = torch.relu(test_Z1)\n",
    "\n",
    "test_Z2 = torch.matmul(w2, test_A1) + b2\n",
    "test_A2 = torch.sigmoid(test_Z2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "906e099f-1924-4e23-8c13-69431fd7ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = (test_A2 >= 0.5).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49e9f1ee-06e9-4346-bfee-586b20057177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "         1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "         1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "         1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "         1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "         1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "         0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "         0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "         0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "         0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "         0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "         1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "         1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "         1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "         1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35f4ff1f-d82a-4e9d-a7e4-826f66df9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = test_A2.squeeze().cpu().detach().numpy()  # Convert to NumPy for CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70a3034a-dc31-44b7-8f98-005c25f90cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.93108749e-01, 9.90953088e-01, 9.73390460e-01, 7.38606602e-02,\n",
       "       1.39745353e-02, 9.08041775e-01, 9.63401854e-01, 9.84901965e-01,\n",
       "       9.77720022e-01, 8.04153383e-01, 9.91400898e-01, 1.98115502e-02,\n",
       "       9.88853335e-01, 9.85260665e-01, 2.09158987e-01, 1.61510217e-03,\n",
       "       8.99447680e-01, 7.96839297e-01, 6.61294237e-02, 9.36185126e-04,\n",
       "       3.00977170e-01, 7.27620423e-02, 8.94426346e-01, 9.91838872e-01,\n",
       "       9.05807078e-01, 3.28235775e-01, 4.02877759e-03, 9.92687702e-01,\n",
       "       9.48047340e-01, 6.21690571e-01, 9.69919503e-01, 9.76192772e-01,\n",
       "       8.44778657e-01, 9.79111910e-01, 8.17008436e-01, 9.57372308e-01,\n",
       "       2.63905883e-01, 9.51115966e-01, 8.52480352e-01, 9.00979638e-01,\n",
       "       8.36312056e-01, 9.38207507e-01, 9.55059603e-02, 9.50962543e-01,\n",
       "       9.68384564e-01, 3.09221774e-01, 2.45900434e-02, 9.82563317e-01,\n",
       "       1.76036537e-01, 8.80445302e-01, 9.78822529e-01, 9.90248621e-01,\n",
       "       9.91860092e-01, 9.89055991e-01, 9.89233494e-01, 9.81396377e-01,\n",
       "       9.80296373e-01, 9.67142045e-01, 9.57563639e-01, 9.82833505e-01,\n",
       "       8.42721462e-01, 9.80383456e-01, 9.84490216e-01, 8.99865746e-01,\n",
       "       4.76471633e-01, 1.98361799e-01, 1.01365626e-01, 7.51714170e-01,\n",
       "       9.40620422e-01, 2.08790768e-02, 9.92431879e-01, 9.20012534e-01,\n",
       "       9.50276732e-01, 9.65001106e-01, 9.80010748e-01, 9.12287712e-01,\n",
       "       9.53454792e-01, 9.81700122e-01, 7.88628936e-01, 9.86683547e-01,\n",
       "       9.79269683e-01, 9.96203840e-01, 2.08847776e-01, 9.47234869e-01,\n",
       "       9.85494971e-01, 9.71969247e-01, 9.86668825e-01, 8.98631215e-01,\n",
       "       9.80459571e-01, 9.30872083e-01, 9.49333370e-01, 9.43357229e-01,\n",
       "       9.59322751e-01, 9.24047351e-01, 9.93080199e-01, 9.22881067e-01,\n",
       "       9.95838761e-01, 9.17614043e-01, 9.05820489e-01, 8.12864602e-01,\n",
       "       9.92510200e-01, 9.33891535e-01, 9.24366534e-01, 9.98415232e-01,\n",
       "       9.87181485e-01, 9.60530281e-01, 9.87501502e-01, 9.54369605e-01,\n",
       "       9.85394597e-01, 9.49954331e-01, 9.84092951e-01, 7.61454761e-01,\n",
       "       9.17344093e-01, 9.96212721e-01, 9.91434872e-01, 9.44150567e-01,\n",
       "       9.36722457e-01, 9.28659141e-01, 9.39119637e-01, 9.76218760e-01,\n",
       "       6.41672313e-01, 8.95250380e-01, 8.32565248e-01, 4.43690032e-01,\n",
       "       9.86516356e-01, 7.21820593e-01, 9.98170376e-01, 9.91682529e-01,\n",
       "       9.90438282e-01, 9.78255928e-01, 9.79059577e-01, 9.72962558e-01,\n",
       "       8.73864770e-01, 9.57020819e-01, 9.94525790e-01, 9.45151508e-01,\n",
       "       9.88889813e-01, 9.89407241e-01, 9.92764175e-01, 9.97857511e-01,\n",
       "       9.95553553e-01, 4.95463789e-01, 5.75391054e-02, 9.77044582e-01,\n",
       "       9.92753446e-01, 9.93830800e-01, 9.97124493e-01, 1.35541528e-01,\n",
       "       9.91470873e-01, 8.04700434e-01, 9.95393395e-01, 9.35020864e-01,\n",
       "       9.90942895e-01, 4.39548939e-01, 9.61104572e-01, 9.64175224e-01,\n",
       "       4.20312017e-01, 9.67495739e-01, 9.72941935e-01, 9.11638141e-01,\n",
       "       9.09594417e-01, 9.86712933e-01, 1.76057905e-01, 2.82164991e-01,\n",
       "       1.73769549e-01, 2.84167618e-01, 9.56425369e-01, 9.78195250e-01,\n",
       "       9.82406497e-01, 2.17079788e-01, 9.41705048e-01, 6.41455472e-01,\n",
       "       9.76755559e-01, 3.13549042e-01, 9.12359476e-01, 9.91475344e-01,\n",
       "       9.85813439e-01, 9.92809892e-01, 9.93523121e-01, 8.51759791e-01,\n",
       "       9.79792953e-01, 9.54058409e-01, 2.25399733e-01, 9.79905546e-01,\n",
       "       5.38950264e-01, 5.34574449e-01, 3.17767292e-01, 9.16169286e-01,\n",
       "       9.86862183e-01, 8.92130852e-01, 9.18578565e-01, 9.33525741e-01,\n",
       "       6.71160579e-01, 1.22391619e-01, 3.35119992e-01, 4.15579230e-01,\n",
       "       1.63997442e-01, 6.99676871e-01, 8.94229710e-01, 2.79004514e-01,\n",
       "       2.78968185e-01, 9.49550688e-01, 6.20302200e-01, 9.76186752e-01,\n",
       "       9.73188579e-01, 3.07752281e-01, 9.90466535e-01, 9.46860254e-01,\n",
       "       5.87852180e-01, 3.28374654e-01, 8.27073812e-01, 6.85599327e-01,\n",
       "       9.56530273e-01, 9.07785714e-01, 9.98714685e-01, 9.61069345e-01,\n",
       "       9.78465974e-01, 9.48839366e-01, 3.38461101e-02, 9.89284933e-01,\n",
       "       4.32503015e-01, 9.95864987e-01, 9.64930177e-01, 9.48613405e-01,\n",
       "       9.82425392e-01, 4.80355024e-01, 9.19867933e-01, 9.71835256e-01,\n",
       "       9.33932185e-01, 6.57558203e-01, 4.40071046e-01, 6.60076559e-01,\n",
       "       9.84947860e-01, 9.97342765e-01, 9.91308033e-01, 5.90711087e-02,\n",
       "       2.60660678e-01, 4.68467295e-01, 9.72753823e-01, 4.31277722e-01,\n",
       "       9.40873921e-01, 8.87785316e-01, 9.29054201e-01, 4.03709739e-01,\n",
       "       9.91157591e-01, 9.11289275e-01, 9.70047474e-01, 4.22670603e-01,\n",
       "       9.19545770e-01, 9.56283748e-01, 8.16489816e-01, 9.20842767e-01,\n",
       "       6.48034453e-01, 6.66473985e-01, 9.95126963e-01, 9.85287666e-01,\n",
       "       9.89073098e-01, 9.82734859e-01, 9.92140591e-01, 1.34590253e-01,\n",
       "       9.41435039e-01, 9.92998600e-01, 9.91892695e-01, 9.81244266e-01,\n",
       "       9.09861565e-01, 5.36647558e-01, 2.10952833e-01, 9.10643756e-01,\n",
       "       9.67998922e-01, 6.03046715e-01, 3.09649527e-01, 9.83877003e-01,\n",
       "       5.18047452e-01, 2.29254141e-01, 8.71135592e-01, 9.88627970e-01,\n",
       "       1.03191510e-01, 4.79150236e-01, 7.29297325e-02, 7.76211977e-01,\n",
       "       4.84383285e-01, 2.35289022e-01, 9.33390379e-01, 2.32386529e-01,\n",
       "       2.89540648e-01, 4.40530211e-01, 3.55392396e-01, 9.27543283e-01,\n",
       "       8.67397904e-01, 5.75953007e-01, 7.64759660e-01, 9.67451870e-01,\n",
       "       8.70579302e-01, 8.99988770e-01, 9.56198812e-01, 9.35486138e-01,\n",
       "       8.62827659e-01, 8.57119918e-01, 8.93801510e-01, 8.83373022e-01,\n",
       "       9.34526682e-01, 3.61792356e-01, 9.00262654e-01, 8.79956067e-01,\n",
       "       9.68957126e-01, 9.18192565e-01, 9.23802495e-01, 4.98059392e-01,\n",
       "       8.89209747e-01, 6.88841939e-01, 4.88349169e-01, 9.45128262e-01,\n",
       "       8.83258358e-02, 9.59037304e-01, 8.95868897e-01, 6.70284510e-01,\n",
       "       9.49343503e-01, 9.64631259e-01, 9.54544723e-01, 1.00460254e-01,\n",
       "       8.17875445e-01, 9.27009284e-01, 8.94786596e-01, 9.79805410e-01,\n",
       "       9.52606499e-01, 9.56974328e-01, 9.33650792e-01, 9.26404119e-01,\n",
       "       9.05991137e-01, 9.83057916e-01, 6.89044893e-01, 5.89251578e-01,\n",
       "       7.11412191e-01, 5.75699449e-01, 2.43740067e-01, 9.60070133e-01,\n",
       "       1.96532663e-02, 9.83310819e-01, 9.55568612e-01, 9.64565933e-01,\n",
       "       9.22883511e-01, 9.84509289e-01, 8.59044850e-01, 9.38780904e-01,\n",
       "       7.50397384e-01, 2.34815940e-01, 9.16665435e-01, 9.76898313e-01,\n",
       "       9.29988086e-01, 9.36436951e-01, 7.30349422e-01, 8.67664099e-01,\n",
       "       7.08065331e-01, 8.69771898e-01, 9.60848153e-01, 9.77576256e-01,\n",
       "       9.75098193e-01, 9.71256375e-01, 9.53761697e-01, 9.87845361e-01,\n",
       "       1.64921686e-01, 5.26539505e-01, 9.82228339e-01, 9.89696026e-01,\n",
       "       9.90627408e-01, 9.86995041e-01, 9.90121365e-01, 4.96559739e-01,\n",
       "       9.89153683e-01, 9.81549680e-01, 7.59842336e-01, 7.72938728e-01,\n",
       "       8.90537798e-01, 9.65726793e-01, 9.89594698e-01, 9.34217215e-01,\n",
       "       9.92127061e-01, 9.53240097e-01, 9.66792285e-01, 9.49116886e-01,\n",
       "       2.58965371e-03, 1.88016202e-02, 9.46030736e-01, 1.42959703e-03,\n",
       "       1.30995817e-04, 9.90457773e-01, 9.84649003e-01, 9.89108205e-01,\n",
       "       5.77815354e-01, 9.89379108e-01, 8.63421679e-01, 3.22930038e-01,\n",
       "       8.41282368e-01, 9.66433823e-01, 7.31022894e-01, 9.83034253e-01,\n",
       "       9.85392511e-01, 1.57472908e-01, 9.66768742e-01, 3.83741170e-01,\n",
       "       9.61694479e-01, 9.71829891e-01, 9.69013572e-01, 9.02261615e-01,\n",
       "       9.80069399e-01, 9.79228139e-01, 7.68580854e-01, 1.97250381e-01,\n",
       "       9.67925549e-01, 4.21508193e-01, 9.38924551e-01, 9.76911604e-01,\n",
       "       9.19200003e-01, 9.84833166e-02, 9.40269828e-01, 9.90413725e-01,\n",
       "       9.56350327e-01, 9.90453482e-01, 9.04048860e-01, 9.69607532e-01,\n",
       "       9.94086504e-01, 6.14075124e-01, 8.40358734e-01, 4.46857184e-01,\n",
       "       9.55612242e-01, 9.92221892e-01, 9.84945118e-01, 9.87592995e-01,\n",
       "       9.89256680e-01, 9.73460972e-01, 9.26707268e-01, 9.37306046e-01,\n",
       "       9.85750794e-01, 9.89742696e-01, 9.89019692e-01, 9.85225499e-01,\n",
       "       6.71148539e-01, 2.39755869e-01, 8.70612442e-01, 6.50575340e-01,\n",
       "       9.36439574e-01, 9.88690197e-01, 5.80069900e-01, 9.74482656e-01,\n",
       "       5.86591303e-01, 9.92695212e-01, 9.87694860e-01, 9.87403750e-01,\n",
       "       9.49008703e-01, 6.24169111e-01, 9.97499168e-01, 9.93394315e-01,\n",
       "       9.95160639e-01, 9.53112364e-01, 9.63060558e-01, 9.08966362e-01,\n",
       "       8.96991432e-01, 9.89310980e-01, 9.96606112e-01, 9.65512812e-01,\n",
       "       9.82803464e-01, 8.02225351e-01, 9.63840544e-01, 8.11503708e-01,\n",
       "       9.36383784e-01, 9.75723922e-01, 8.91111851e-01, 9.79722023e-01,\n",
       "       9.62527275e-01, 9.94003832e-01, 9.67175245e-01, 9.72651184e-01,\n",
       "       9.69656646e-01, 9.48580146e-01, 8.98034453e-01, 9.59627330e-01,\n",
       "       9.55667973e-01, 9.70595658e-01, 9.59034979e-01, 9.76428330e-01,\n",
       "       9.18987930e-01, 9.85110879e-01, 9.84044433e-01, 9.67443526e-01,\n",
       "       9.81498539e-01, 8.67037714e-01, 9.53032255e-01, 9.91795242e-01,\n",
       "       9.90881801e-01, 5.23741305e-01, 7.57290542e-01, 9.61642802e-01,\n",
       "       9.96852100e-01, 9.58058715e-01, 9.93964851e-01, 9.74498868e-01,\n",
       "       9.54759419e-01, 9.81266737e-01, 9.86360908e-01, 9.87561703e-01,\n",
       "       9.83037829e-01, 8.57063115e-01, 9.75154400e-01, 9.57247972e-01,\n",
       "       9.77782786e-01, 9.97498810e-01, 9.99242783e-01, 9.42216694e-01,\n",
       "       1.66778341e-01, 9.42222551e-02, 3.76905091e-02, 9.71258461e-01,\n",
       "       9.59324300e-01, 9.98319089e-01, 6.13305807e-01, 5.55219166e-02,\n",
       "       9.86438632e-01, 6.53956771e-01, 9.62344766e-01, 7.77490065e-02,\n",
       "       7.24027678e-02, 2.32322395e-01, 4.59996313e-01, 8.46692562e-01,\n",
       "       8.10989082e-01, 9.96771276e-01, 8.15570205e-02, 9.63291466e-01,\n",
       "       1.09866433e-01, 9.01540399e-01, 1.79087296e-01, 9.90132093e-01,\n",
       "       5.08991182e-01, 9.97378588e-01, 1.35672346e-01, 9.87074137e-01,\n",
       "       1.28015310e-01, 4.61905211e-01, 8.53632927e-01, 8.05058539e-01,\n",
       "       3.96150261e-01, 9.78253424e-01, 8.88011038e-01, 9.34083700e-01,\n",
       "       9.96321321e-01, 8.89542282e-01, 9.89815593e-01, 8.65318924e-02,\n",
       "       8.41810346e-01, 3.56710047e-01, 2.87668198e-01, 3.84783804e-01,\n",
       "       1.53989464e-01, 8.89529169e-01, 9.48848128e-01, 1.74794421e-01,\n",
       "       3.03004831e-01, 7.65692592e-01, 7.09942162e-01, 2.50091106e-02,\n",
       "       5.36982305e-02, 1.48693144e-01, 4.15127724e-01, 1.00513980e-01,\n",
       "       2.79647142e-01, 8.95987451e-01, 7.58326709e-01, 8.47087130e-02,\n",
       "       9.35929537e-01, 4.21630770e-01, 6.21433258e-01, 5.44168949e-01,\n",
       "       9.03709352e-01, 6.38841987e-02, 2.53629684e-01, 8.84671450e-01,\n",
       "       9.68419671e-01, 3.24059486e-01, 9.36548486e-02, 9.86758530e-01,\n",
       "       9.07423913e-01, 9.63639736e-01, 7.86707282e-01, 7.16735870e-02,\n",
       "       4.34883595e-01, 9.90016162e-01, 1.19541243e-01, 9.59971666e-01,\n",
       "       8.33754778e-01, 9.92313683e-01, 9.87909555e-01, 6.48946702e-01,\n",
       "       9.98162210e-01, 6.19366586e-01, 9.61117983e-01, 9.83013570e-01,\n",
       "       9.25514996e-01, 9.47697163e-01, 9.66701150e-01, 8.90753031e-01,\n",
       "       9.95549560e-01, 6.56693399e-01, 9.74019885e-01, 9.97730315e-01,\n",
       "       5.23193896e-01, 3.86419922e-01, 6.47465765e-01, 9.96113300e-01,\n",
       "       5.92999041e-01, 9.96077836e-01, 7.34175026e-01, 3.63098115e-01,\n",
       "       9.89398122e-01, 9.75422800e-01, 9.86404300e-01, 9.87593353e-01,\n",
       "       4.09759909e-01, 3.82059753e-01, 9.86312926e-01, 9.92814481e-01,\n",
       "       1.26909018e-01, 9.99095082e-01, 9.39671576e-01, 9.98773515e-01,\n",
       "       9.98641431e-01, 6.29644513e-01, 8.72307539e-01, 8.55873823e-02,\n",
       "       2.63561100e-01, 6.64377332e-01, 3.27061534e-01, 9.62097168e-01,\n",
       "       3.10767323e-01, 9.98981059e-01, 9.71370399e-01, 8.12096536e-01,\n",
       "       1.41443193e-01, 9.55359221e-01, 4.97773468e-01, 9.93599415e-01,\n",
       "       1.09961256e-01, 9.62403476e-01, 9.42350984e-01, 6.45154357e-01,\n",
       "       3.68315578e-01, 8.82289350e-01, 2.11191401e-01, 9.05189455e-01,\n",
       "       9.45663154e-01, 8.96894336e-01, 1.49845872e-02, 5.01877725e-01,\n",
       "       8.08262110e-01, 9.01014388e-01, 2.86941290e-01, 9.12215829e-01,\n",
       "       9.00558233e-01, 8.84506345e-01, 9.64511037e-01, 8.18813920e-01,\n",
       "       7.94262171e-01, 9.22194660e-01, 8.85016739e-01, 9.44204152e-01,\n",
       "       9.68341649e-01, 9.52785015e-01, 9.12318885e-01, 9.07783926e-01,\n",
       "       6.99948251e-01, 9.54573750e-01, 7.65778005e-01, 9.16511297e-01,\n",
       "       8.98831725e-01, 9.61891234e-01, 9.20325518e-01, 5.76122522e-01,\n",
       "       9.69621539e-01, 9.15717006e-01, 9.22937453e-01, 2.68874735e-01,\n",
       "       2.65625209e-01, 9.64184880e-01, 9.87079561e-01, 9.55696523e-01,\n",
       "       9.70010281e-01, 9.53800619e-01, 2.29667768e-01, 9.83321786e-01,\n",
       "       9.31984484e-01, 9.55350399e-01, 9.49770987e-01, 9.87135708e-01,\n",
       "       9.54328299e-01, 9.51738596e-01, 2.34590605e-01, 9.53375518e-01,\n",
       "       9.09532845e-01, 5.50504804e-01, 9.83596981e-01, 5.13445772e-02,\n",
       "       7.74632871e-01, 9.87324715e-01, 8.80767107e-01, 1.86404139e-01,\n",
       "       1.05781145e-01, 5.89306891e-01, 8.64322543e-01, 9.13079306e-02,\n",
       "       6.92526856e-03, 8.26451361e-01, 7.36245587e-02, 9.58920658e-01,\n",
       "       8.74083564e-02, 5.44872403e-01, 9.77785349e-01, 9.50057864e-01,\n",
       "       6.84284508e-01, 9.67493176e-01, 9.73380387e-01, 8.42553794e-01,\n",
       "       7.35760450e-01, 9.19238269e-01, 9.51407313e-01, 9.79663312e-01,\n",
       "       9.86021101e-01, 9.83732283e-01, 8.81720185e-01, 9.81531739e-01,\n",
       "       9.91675079e-01, 9.10222828e-01], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7de6d374-6c91-42fa-9702-d742b9d609ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Submission file saved as 'submission.csv'. Ready for Kaggle upload! ðŸŽ¯\n"
     ]
    }
   ],
   "source": [
    "k_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# Ensure y_test_prob is a NumPy array and has correct shape\n",
    "y_test_prob = y_test_prob.flatten()  # Flatten to ensure it's 1D\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": k_test[\"id\"],  # Use the row index as ID\n",
    "    \"rainfall\": y_test_prob  # Use predicted probabilities\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Submission file saved as 'submission.csv'. Ready for Kaggle upload! ðŸŽ¯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed11aeb6-645b-498a-aac3-58c2db534d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
